---
title: Hadoop知识点
date: 2017-05-08 23:43:49
tags: [大数据,hadoop]
categories: [大数据,hadoop]
---
#Hadoop数据管理
主要包括Hadoop的分布式文件系统HDFS、分布式数据库HBase和数据仓库工具Hive

##HDFS的数据管理
HDFS是分布式计算的存储基石，Hadoop分布式文件系统和其它文件系统有很多类似的特性；  
1）对于整个集群有单一的命名空间；  
2）具有数据一致性，都适合一次写入多次读取的模型，客户端在文件没有被成功创建之前是无法看到文件存在的。  
3）文件会被分割成多个文件块，每个文件块被分配存储到数据节点上，而且会根据配置由复制文件块来保证数据的安全性。  
HDFS有三个重要的角色来进行文件系统的管理：NameNode、DataNode和Client。NameNode可以看做是分布式文件系统的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode会将文件系统的Metadata存储在内存中，这些信息主要包括文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode中的信息等。DataNode是文件存储的基本单元，它将文件块（Block）存储在本地文件系统中，保存了所有Block的Metadata，同时周期性地将所有存在的Block信息发送给NameNode。Client就是需要获取分布式文件系统文件的应用程序。接下来三个具体的操作来说明HDFS对数据的管理。  
（1）文件写入
1）Client向NameNode发起文件写入的请求。  
2）NameNode根据文件的大小和文件块配置情况，返回给Client所管理的DataNode的信息。  
3）Client将文件划分为多个Block，根据DataNode的地址信息，按顺序将其写入到每一个DataNode块中。  
（2）文件读取  
1）Client向NameNode发起文件读取的请求。  
2）NameNode返回文件存储的DataNode信息。  
3）Client读取文件信息。  
（3）文件块（Block）复制  
1）NameNode发现部分文件的Block不符合最小复制数这一要求或部分DataNode失效。  
2）通知DataNode相互复制Block。  
3）DataNode开始直接相互复制。  

作为分布式文件系统，HDFS在数据管理方面还有值得借鉴的几个功能：  
a.文件块（Block）的放置：一个Block会有三份备份，一份放在NameNode指定的DataNode上，另一份放在与指定DataNode不在同一机器上的DataNode上，最后一份放在与指定DataNode同一Rack的DataNode上。备份的目的是为了数据安全，采用这种配置方式主要是考虑同一Rack失败的情况，以及不同Rack之间进行数据复制会带来的性能问题。  
b.心跳检测：用心跳检测DataNode的健康状况，如果发现问题就采取数据备份的方式来保证数据的安全性。  
c.数据复制（场景为DataNode失败、需要平衡DataNode的存储利用率和平衡DataNode数据交互压力等情况）；使用Hadoop时可以用HDFS的balancer命令配置Threshold来平衡每一个DataNode的磁盘利用率。假设设置了Threshold为10%，那么执行balancer命令时，首先会统计所有的DataNode的磁盘利用率的平均值，然后判断如果某一个DataNode的磁盘利用率超过这个平均值，那么将会把这个DataNode的Block转移到磁盘利用率低的DataNode上，这对于新的节点为加入十分有用。  
d.数据校验：采用CRC32做数据校验。在写入文件块的时候，除了会写入数据外还会写入校验信息，在读取的时候则需要先校验后读入。  
e.数据管道性的写入：当客户端要写入文件到DataNode上时，首先会读取一个Block，然后将其写到每一个DataNode上，接着由第一个DataNode将其传递到备份的DataNode上，直到所有需要写入这个Block的DataNode都成功写入后，客户端才会开始写下一个Block。  
f.安全模型：分布式文件系统启动时会进入安全模式（系统运行期间也可以通过命令进入安全模式），当分布式文件处于安全模式时，文件系统中的内容不允许修改也不允许删除，直到安DataNode上数据块的有效性，同时根据策略进行必要的复制或删除部分数据块。在实际操作过程中，如果在系统启动时修改和删除文件会出现安全模式不允许修改的错误提示，只需要等待一会即可。  


##HBase的数据管理
HBase是一个类似Bigtable的分布式数据库，它的大部分特性和Bigtable一样，是一个稀疏的、长期存储的（存在硬盘上）、多维度的排序映射表，这张表的索引是行关键字、列关键字和时间戳。表中的每个值是一个纯字符数组，数据都是字符串，没有类型，所以同一张表中的每一行数据都可以有截然不同的列。列名字的格式是“<family>:<label>"，它是由字符串组成的，每一张表有一个family集合，这个集合是固定不变的，相当于表的结构，只能通过改变表结构来改变表的family集合。但是label值相对于每一行来说都是可以改变的。  
HBase把同一个family中的数据存储在同一个目录下，而HB的写操作是锁行的。每一行都是一个原子元素，都可以加锁。所有数据库的更新都有一个时间戳标记，每次更新都会生成一个新的版本，而HBase会保留一定数量的版本，这个值是可以设定的。客户端可以选择获取距离某个时间点最近的版本，或者一次获取所有版本。  

以上从微观上介绍了HBase的一些数据管理措施，那么HBase作为分布式数据为顺整体上从集群出发又是如何管理数据的呢？  
HBase在分布式集群上主要依赖于HRegion、HMaster、HClient组成的体系结构从整体上管理数据。  
HBase体系结构有三大重要组成部分：  
a.HBaseMaster：HBase主服务器，与Bigtable的主服务器类似。  
b.HRegionServer：HBase域服务器，与Bigtable的Tablet服务器类似。  
c.Hbase Client：HBase客户端是由org.apache.hadoop.Hbase.client.HTable定义的。  
下面将对这三个组件进行详细的介绍。  
（1）HBaseMaster  
一个HBase只部署一台主服务器，它通过领导选举算法确保只有唯一的主服务器是活跃的，ZooKeeper保存主服务器的服务器地址信息。如果主服务器瘫痪，可以通过领导选举算法从备用服务器中选择新的主服务器。  
主服务器承担着初始化集群的任务。当主服务器每一次启动时，会试图从HDFS获取根或根域目录，如果获取失败则创建根或根域目录，以及第一个元域目录。在下次启动时，主服务器就可以获取集群和集群中所有域 的信息了。同时主服务器还负责集群中域的分配、域服务器运行状态的监控、表格的管理等工作。  


（2）HRegionServer  
HBase域服务器的主要职责有服务于主服务器分配的域、处理端的读写请求、本地缓冲回写、本地数据压缩和分割域等功能。  
每个域只能由一台域服务器来提供服务。当它开始服务于某域时，它会从HDFS文件系统中读取该域的日志和所有存储文件，同时还会管理操作HDFS文件的持久性存储工作。客户端通过与主服务器通信获取域或域服务器的列表信息后，就可以直接向域服务器发送域读写请求，来完成操作。  

（3）HBaseClient  
 HBase客户端负责查找用户域所在的域服务器地址。HBase客户端会与HBase主机交换消息以查找根域的位置，这是两者之间唯一的交流。  
定位根域后，客户端连接根域所在的服务器，并扫描根域获取元域信息。元域信息中包含所需用户域的域服务器地址。客户端再连接元域所在的服务器，扫描元域以获取所需用户域所在的域服务器地址。客户端再连接元域所在的域服务器，扫描元域以获取所需用户域所有的域服务器地址。定位用户域后，客户端连接用户域所在的域服务器并发出读写请求。用户域的地址将在客户端被缓存，后续的请求无须重复上述过程。  

综上所述，HBase的体系结构中，HBase主要由主服务器、域服务器和客户端三部分组成。主服务器作为HBase的中心，管理整个集群中的所有域，监控每台域服务器的运行情况等；域服务器接收来自服务器的分配域，处理管理端的域读写请求并回写映射文件等；客户端主要用来查找用户域所在的域服务器地址信息。  


##Hive的数据管理  
Hive是建立在Hadoop上的数据仓库基础架构。它提供了一系列的工具，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。Hive定义了简单的类SQL的查询语言，称为HiveQL，它允许熟悉SQL的用户用SQL语言查询数据。作为一个数据仓库，Hive的数据管理按照使用层次可以从元数据存储、数据存储和数据交换三方面来介绍。  
（1）元数据存储  
Hive将元数据存储在RDBMS中，有三种模式可以连接到数据库。  
1）Single User Mode:此模式连接到一个In-memory的数据库Derby，一般用于Unit Test。  
2）Multi User Mode：通过网络连接到一个数据库中，这是最常用的模式。  
3）Remote Server Mode：用于非Java客户端访问元数据，在服务器端启动一个MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer来访问元数据库。  
（2）数据存储  
首先，Hive没有专门的数据存储格式，也没有为数据建立索引，用户可以非常自由地组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符，它就可以解析数据了。  
其次，Hive中所有的数据都存储在HDFS中，Hive中包含4种数据模型：Table、External Table、Partition和Bucket。  
Hive中的Table和数据库中的Table在概念上是类似的，每一个Table在Hive中都有一个相应的目录来存储数据。例如，一个表pvs，它在HDFS中的路径为:/wh/pvs，其中wh是在hive-site.xml中由${hive.metastore.warehouse.dir}指定的数据仓库的目录，所有的Table数据（不包括External Table）都保存在这个目录中。  
（3）数据交换
数据交换主要分为以下部分，如图：



a）用户接口：包括客户端、Web界面和数据库接口。  
b)元数据存储：通常存在在关系型数据库中，如MYSQL、Derby中。  
c)解释器、编译器、优化器、执行器。  
d)Hadoop：利用HDFS进行存储，利用MapRecue进行计算。  
用户接口主要有三个：客户端、数据库接口和Web界面，其中最常用的是客户端。Client是Hive的客户端，当启动Client模式时，用户会想要连接Hive Server，这时需要指出Hive Server所在的节点，并且在该节点启动HiveServer。Web界面是通过浏览器访问Hive的。  
Hive元数据存储在数据库中，如MYSQL、Derby中。Hive中的元数据包括表的名字、表的列、表的分区、表分区的属性、表的属性、表的数据所在目录等。    
解释器、编译器、优化器完成HiveQL查询语句从记法分析、语法分析、编译、优化到查询计划的生成。生成的查询计划存储在HDFS中，并且随后由MapRecue调用执行。  
Hive的数据存储在HDFS中，大部分的查询由MapRecue完成（包括*的查询不会生成MapRecue任务，比如select * from tbl).  




#安装并运行Hadoop
介绍Hadoop安装之前，先介绍一下Hadoop对各个节点的角色定义。
Hadoop分别从三个角度将主机划分为两种角色。第一，最基本的划分为Master和Slave，即主人和奴隶；第二，从HDFS的角度，将主机划分为NameNode和DataNode（在分布式文件系统中，目录的管理很重要，管理目录相当于主人，而NameNode就是目录管理者）；第三，从MapRecue的角度，将主机划分为JobTracker和TaskTracker（一个Job经常被划分为多个Task，从这个角度不难理解它们之间的关系）。
