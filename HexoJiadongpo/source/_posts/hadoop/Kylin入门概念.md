---
title: Kylin入门概念
date: 2017-04-16 23:43:49
tags: [大数据,kylin]
categories: [大数据,kylin]
---

#Apache Kylin的工作原理
Apache Kylin的工作原理本质上是MOLAP（Multidimensional　Online　Analytical　Processing）Cube，也就是多维　立方体分析。这是数据分析中相当经典的理论，在关系数据库年代就已经有了广泛的应用，下面将其做简要的介绍。  

##维度和度量
简单来讲，维度就是观察数据的角度。比如电商的销售数据，可以从时间的维度来观察，也可以进一步细化，从时间和地区的维度来观察。维度一般是一组离散的值，比如时间维度上的每一个独立的日期，或者商品维度上的每一件独立的商品。因此统计时可以把维度值 相同的记录聚合在一起，然后应用聚合函数做累加、平均、去重计数等聚合计算。  !["维度和度量的例子"](/images/hadoop/kylin/维度和度量的例子.jpg)
    
度量就是被聚合的统计值，也是聚合运算的结果，它一般是连续的值，如图1-2中的销售额，抑或是销售商品的总件数据 。通过比较和测量试题，分析师可以对数据进行评估，比如今年的销售额相比去年有多大的增长，增长的速度是否达到预期，不同商品类别的增长比例是否合理等。  

##Cube和Cuboid
有了维度和度量，一个数据表或数据模型上的所有字段就可以分类了，它们要么是维度，要么是度量（可以被聚合）。于是就有了根据维度和度量来做预计算的Cube理论。  
给定一个数据模型，我们可以对其上的所有维度进行组合。对于N个维度来说，组合的所有可能共2的n次方种。对于每一种维度的组合，将度量做聚合运算，然后将运算的结果保存为一个物化视图，称为Cuboid。所有维度组合的Coboid作为一个整体，被称为Cube。所以简单来说一个Cube就是许多按维度聚合的物化视图的集合。  
下面来举一个具体的例子。假定有一个电商的销售数据集，其中维度包括时间（Time）、商品（Item）、地点（Location）和供应商（Supplier），度量为销售额（GMV）。那么所有维度的组合就有2的4次方=16种，比如一维度（ID）的组合有[Time]、[Item]、[Location]、[Supplier]4种；二维度（3D）的组合有[Time,Item]、[Time，Location]、[Time,Supplier]、[Item,Location]、[Item,Supplier]、[Location,Supplier]6种；三维度（3D）的组合也有4种；最后零维度（0D）和四维度（4D）的组合各有1种，总共有16种组合。
!["一个四维Cube的例子"](/images/hadoop/kylin/一个四维Cube的例子.jpg)
		
计算Cuboid，即按维度来聚合销售额。如果用SQL语句来表达计算Cuboid[Time,Location]，那么SQL语句如下：  
Select Time,Location,Sum(GMV) as GMV from Sales group by Time,Location.  
将计算的结果保存为物化视图，所有Cuboid物化视图的总称是Cube。

##工作原理
Apache Kylin的工作原理就是对数据模型做Cube预计算，并利用计算的结果加速查询，具体工作过程如下：
1）指定数据模型，定义维度和度量
2）预计算Cube，计算所有Cuboid并保存为物化视图。
3）执行查询时，读取Cuboid，运算，产生查询结果。
由于Kylin的查询过程不会扫描原始记录，而是通过预计算预先完成表的关联、聚合等复杂运算，并利用预计算的结果来执行查询，因此相比非预计算的查询技术，其速度一般要快一到两个数据级，并且这点在超磊的数据集上优势更加明显。当数据集达到千亿及至万亿级别时，Kylin的速度甚至可以超越其他非预计算技术1000倍以上。

#技术架构
Apache Kylin系统可以分为在线查询和离线构建两部分，技术架构如下图所示，在线查询的模块主要处于上半区，而离线构建则处于下半区。
!["Kylin的技术架构"](/images/hadoop/kylin/Kylin的技术架构.jpg)	

我们首先看看离线构建的部分。从图1-4可以看出，数据源在左侧，目前主要是Hadoop Hive，保存着待分析的用户数据。根据元数据的字义，下方构建引擎从数据源抽取数据，并构建Cube。数据以关系表的形式输入，且必须符合星形模型（Star Schema）（更复杂的雪花模型在成文时还不支持，可以通过视图将雪花模型转化为星形模型，再使用Kylin）。MapRecue是当前主要的构建技术。构建后的Cube保存在右侧的存储引擎中，一般选用HBase作为存储。  
完成了离线构建之后，用户可以从上方查询系统发送SQL进行查询分析。Kylin提供了各种Rest　API、ＪＤＢＣ／ＯＤＢＣ接口。无论从哪个接口进入，SQL最终都会来到Rest服务层，再转交给查询引擎进行处理。这里需要注意的是，SQL语句是基于数据源的关系模型书写的，而不是Cube。Kylin在设计时刻意对查询用户屏蔽了Cube的概念，分析师只需要理解简单的关系模型就可以使用Kylin，没有额外的学习门槛，传统的SQL应用也很容易迁移。查询引擎解析SQL，生成基于关系表的逻辑执行计划，然后将其转义为基于Cube的物理执行计划，最后查询预计算生成的Cube并产生结果。整个过程不会访问原始数据源。  


**注意**：对于查询引擎下方的路由选择，在最初设计时曾考虑过将Kylin不能执行查询引导去Hive中继续执行，但在实践后发现Hive与Kylin的速度差异过大，导致用户无法对查询的速度有一致的期望，很可能大多数据查询几秒内就返回结果了，而有些查询则要等几分钟到几十分钟，因此体验非常糟糕。最后这个路由功能在发行版中默认关闭。


Apache Kylin 1.5版本引入了“可扩展架构”的概念。在图1-4中显示为三个粗虚框，表示的抽象层。可扩展指Kylin可以对其主要依赖的三个模块做任意的扩展和替换。Kylin的三大依赖模型分别是数据源、构建引擎和存储引擎。在设计之初，作为Hadoop家族 一员，这三者分别是Hive、MapRecue和HBase。但随着推广和使用的深入，渐渐有用户发现它们均存在不足之处。比如，实时分析可能会希望从Kafka导入数据而不是Hive；而Spark的迅速崛起，又使我们不得不考虑将MapRecue替换为Spark，以期大幅提高Cube的构建速度；至于HBase，它的读性能可能还不如Cassandra或Kudu等 。可见，是否可以将一种技术替换为另一种技术已成为一个常见的问题。于在1.5版本的系统架构进行了重构，将数据源、构建引擎、存储引擎三大依赖抽象为接口，而Hive、MapRecue、HBase只是默认实现。深度用户可以根据自己的需要做二次开发，将其中的一个或多个替换为更适合的技术。  

#核心概念
##数据仓库
数据仓库（Data Warehouse）是一种系统的资料储存理论，此理论强调的是利用某些特殊的资料储存方式，让所包含的资料特别有利于分析和处理，从而产生有价值的资讯，并可依此做出决策。
利用数据仓库的方式存放资料，具有一旦存入，便不会随时间发生变动的特性，此外，存入的资料必定包含时间属性，通常一个数据仓库中会含有大量的历史性资料，并且它可利用特定的分析方式，从其中发掘特定的资讯。

##OLAP
OLAP（Online Analytical Process），联机分析处理，以多维度的方式分析数据，而且能够弹性地提供上卷（Roll-up）、下钻（Drill-down）和透视分析（Pivot）等操作，它呈现集成性决策信息的方法，多用于决策支持系统、商务智能或数据仓库。其主要的功能在于方便大规模数据分析及统计计算，可对决策提供参考和支持。与之相区别的是取机交易处理（OLTP），联机交易处理，更侧重于基本的、日常的事务处理，包括数据的增删改查。
OLAP需要以大量历史数据为基础，再配合时间点的差异，对多维度及汇整型的信息进行复杂的分析。
OLAP需要用户有主观的信息需求定义，因此系统效率较佳。
OLAP的概念，在实际应用中存在广义和狭义两种不同的理解方式。广义上的理解与字面上的意义相同，泛指一切不会对数据进行更新的分析处理。但更多的情况下OLAP被理解为其狭义上的含义，即与多维分析相关，基于立方体（Cube）计算而进行的分析。

##BI
BI（Business Intelligence），即商务智能，指现代数据仓库技术、在线分析技术、数据挖掘和数据展现技术进行数据分析以实现商业价值。


##维度和度量
维度和度量是数据分析中的两个基本的概念
**维度**是指审视数据的角度，它通常是数据记录的一个属性，例如时间、地点等。  
**度量**是基于数据所计算出来的考量值；它通常是一个数值，如总销售额、不同的用户数等。分析人员往往要结合若干个维度来审查度量值，以便在其中找到变化规律。在一个SQL查询中，Group By的属性通常就是维度，而所计算的值则是度量。如下面的示例：  
    select part_dt,lstg_iste_id,sum(price) as total_selled,count(distinct seller_id) as sellers from kylin_sales group by part_dt,lstg_site_id

##事实表和维度表
**事实表**（Fact Table）是指存储有事实记录的表，如系统日志、销售记录等；事实表的记录在不断地动态增长，所以它的体积通常远大于其他表。

**维度表**（Dimension Table）或维表，有时也称查找表（Lookup Table），是与事实表相对应的一种表；它保存了维度的属性值，可以跟事实表做关联；相当于将事实表上经常重复出现的属性抽取、规范出来用一张表进行管理。常见的维度表有：日期表（存储与日期对应的周、月、季度等属性）、地点表（包含国家、省、城市等属性）。使用维度表有诸多好处，具体如下：
a.缩小了事实表的大小
b.便于维度的管理和维护，增加、删除和修改维度的属性，不必对事实表的大量记录进行改动。
c.维度表可以为多个事实表重用，以减少重复工作。

##Cube、Cuboid和Cube Segment
###Cube
Cube（或Data Cube），即数据立方体，是一种常用于数据分析与索引的技术；它可以对原始数据建立多维度索引。通过Cube对数据进行分析，可以大大加快数据的查询效率。

###Cuboid
Cuboid在Kylin中特指在某一种维度组合下所计算的数据。

##Cube Segment
Cube Segment是指针对源数据中的某一片段，计算出来的Cube数据。通常数据仓库中的数据数量会随着时间的增长而增长，而Cube Segment也是按时间顺序来构建的。



#在Hive中准备数据
这里介绍准备Hive数据的一些注意事项。需要被分析的数据必须先保存为Hive表的形式，然后Kylin才能从Hive中导入数据，创建Cube。
Hive是一个基于Hadoop的数据仓库工具，可以将结构化的数据文件映射为数据库表，并可以将SQL语句转换为MapRecue或Tez任务进行运行，从而让用户以类SQL（HiveQL，也称HQL）的方式管理和查询Hadoop上的海量数据。
此外，Hive还提供了多种方式（如命令行、API和Web服务等）可供第三方方便地获取和使用元数据并进行查询。今天，Hive已经成为Hadoop数据仓库的首选，是Hadoop上不可或缺的一个重要组件，很多项目都已兼容或集成了Hive。基于此情况，Kylin选择Hive作为原始数据的主要来源。
在Hive中准备待分析的数据是使用Kylin的前提；将数据导入到Hive表中的方法有很多，用户管理数据的技术和工具也各式各样，因此具体步骤不在本书的讨论范围之内。

##星形模型
数据挖掘有几种常见的多维数据模型，如星形模型（Star Schema）、雪花模型（Snowf lake Schema）、事实星座模型（Fact Constellation）等。  
星形模型中有一张事实表，以及零个或多个维度表；事实表与维度表通过主键外键相关联，维度表之间没有关联，就像很多星星围绕在一个恒星周围，帮取名为星形模型。
如果将星形模型中某些维度的表再做规范，抽取成更细的维度表，然后让维度表之间也进行关联，那么这种模型称为雪花模型。
星形模型是更复杂的模型，其中包含了多个事实表，而维度表是公用的，可以共享。
不过，Kylin只支持星形模型的数据集，这是基于以下考虑的。  

- 星形模型是最简单，也是最常用的模型  
- 由于星形模型只有一张大表，因此它相比于其它模型更适合于大数据处理  
- 其他模型可以通过一定的转换，变成星形模型。  

##维度表的设计
除了数据模型以外，Kylin还对维度表有一定的要求，具体要求如下。  


- 要具有数据一致性，主键值必须是唯一的；Kylin会进行检查，如果有两行的主键值相同则会报错。
- 维度越小越好，因为Kylin会将维度表加载到内存中供查询；过大的表不适合作为维度表，默认的阈值是300MB。  
- 改变频率低，Kylin会在每次构建中试图重用维度表的快照，如果维度表经常改变的话，重用就会失效，这就会导致要经常对维度表创建快照。
- 维度表最好不要是Hive视图（View），虽然在Kylin1.5.3中加入了对维度表是视图这种情况的支持，但每次都需要将视图进行物化，从而导致额外的时间开销。

##Hive表分区
Hive支持多分区（Partition）。简单来说，一个分区就是一个文件目录，存储了特定的数据文件。当有新的数据生成的时候，可以将数据加载到指定的分区，读取数据的时候也可以指定分区。对于 SQL查询，如果查询中指定了分区列的属性条件，则Hive会智能地选择特定分区（也就是目录），从而避免全量数据的扫描，减少读写操作对集群的压力。
下面举的一组SQL演示了如何使用分区：  

Hie>create table invites(id int,name string) partitioned by(ds string) row format delimited fields terminated by 't' stroed as textfile;  
Hive>load data local inpath '/user/hadoop/data.txt' overwrite into table invites partition (ds='2016-08-16');  
Hive>select * from invites where ds = '2016-08-16';  
Kylin支持增量的Cube构建，通常是按时间属性来增量地从Hive表中抽取数据。如果Hive表正好是按此时间属性做分区的话，那么就可以利用到Hive分区的好处，每次在Hive构建的时候都可以直接跳过不相干的日期的数据，节省Cube构建的时间。这样的列在Kylin里也称为分割时间列（Partition Time Column），通常它应该也是Hive表的分区列。


##了解维度的基数
维度的基数（Cardinality）指的是该维度在数据集中出现的不同值的个数；例如“国家”是一个维度，如果有200个不同的值，那么此维度的基数就是200.通常一个维度的基数会从几十到几万个不等，个别维度如“用户ID”的基数会超过百万甚至千万。基数超过一百万的维度通常称为超高维度（Ulta Hight Cardinality，UHC），需要引起设计者的注意。  
Cube中所有维度的基数都可以体现Cube的复杂度，如果一个Cube中有好几个超高基数维度，那么这个Cube膨胀就会很高。在创建Cube前需要对所有维度的基数做一个了解，这样就可以帮助设计合理的Cube。计算基数有多种途径，最简单的方法就是让Hive执行一个count distinct的SQL查询；Kylin也提供计算基数的方法，在导入Hive表定义后可以看到每一个列的基数，参数名为Cardinality

##Sample Data
如果需要快速体验Kylin，可以用Kylin自带的Sample Data。运行${KYLIN_HOME}/bin/sample.sh来导入Sample Data，然后就能按照下面的流程来创建模型和Cube。  
具体请执行下面命令，将Sample Data导入到Hive数据库。  
cd ${KYLIN_HOME}  
bin/sample.sh  
Sample Data测试的样例数据集总共仅1M左右，共计3张表，其中事实表有10000条数据。数据集是一个规范的星形模型结构，它总包含3个数据表：    
KYLIN_SALES是事实表，保存了销售订单的明细信息。各列分别保存着卖家、商品、分类、订单金额、商品数据等信息，每一行对应着一笔交易订单。  
KYLIN_CATEGORY_GROUPINGS是维表，保存了商品分类的详细介绍，例如商品分类名称等。  
KYLIN_CAL_DT也是维表，保存了时间的扩展信息。如单个日期所在的年始、月始、周始、年份、月份等。  
这3张表一起构成了整个星形模型。  

#设计Cube
如果数据已经在Hive中准备好了，就可以开始创建Cube了。
##导入Hive表定义
登陆Kylin的Web界面，创建新的或选择一个已有的项目之后，需要做的就是将Hive表的定义导入到Kylin中。  
单击Web界面的Model->Data Source下的”Local Hive Table“图标，然后输入表的名称（可以一次导入多个表，以逗号分隔表名），单击按钮”Sync“，Kylin就会使用Hive的API从Hive中获取表的属性信息。  
导入成功后，表的结构信息会以树状的形式显示在页面的左侧，可以单击展开或收缩。

同时Kylin会在后台触发一个MapRecue任务，计算此表的每个列的基数。通常稍过几分钟后再刷新页面，就会看到显示出来 的基数信息Cardinality

需要注意的是，这里Kylin对基数的计算方法采用的是HyperLogLog的近似算法，与精确值略有误差，只做参考值。

##创建数据模型
有了表信息之后，就可以开始创建数据模型（Data Model）了。数据模型是Cube的基础，它主要用于描述一个星形模型。有了数据模型以后，定义Cube的时候就可以直接从此模型定义的表和列中进行选择了，省去重复指定连接（join）条件的步骤。基于一个数据模型还可以创建多个Cube，以方便减少用户的重复性工作。  
在Kylin界面中”Models“页面中单击”New"->"New Model"，开始创建数据模型。


接下来选择用作维度和度量的列。这里只是选择一个范围，不代表这些列将来一定要用作Cube 的维度或度量，你可以把所有可能会用到表都选进来，后续创建Cube的时候，将只能从这些列中进行选择。   

选择维度列时，维度可以来自事实表或维度表  
选择度量列时，度量只能来自事实表  
最后一步，是为模型补充侵害时间列信息和过滤条件。如果此模型中的事实表记录是按时间增长的，那么可以指定一个日期/时间列作为模型的分割时间列，从而可以让Cube按此列做增量构建。

过滤（Filter）条件是指，如果想把一些记录忽略掉，那么这里可以设置一个过滤条件。Kylin在向Hive请求源数据的时候，会带上此过滤条件。

随后“Save”后，出现在“Model”的列表中。


##创建Cube
单击“New”，选择“New Cube”，会开启一个包含若干步骤的向导。

第一页，选择要使用的数据模型，并为此Cube输入一个唯一的名称（必需的）和描述（可选的）；这里还可以输入一个邮件通知列表，用于在构建完成或出错时收到通知。如果不想接收处于某些状态的通知，那么可以从“Notification Events”中将其去掉。

第二页，选择Cube的维度。可以通过以下两个按钮来添加维度。   
**“Add Mimension”**：逐个添加维度，可以是普通维度也可以是衍生（Derived）维度。
**“Auto Generator”：**批量选择并添加，让Kylin自动完成其它信息。  
使用第一种方法的时候需要为每个维度起个名字，然后选择表和列。  
如果是衍生维度的话，则必须是来自于某个维度表，一次可以选择多个列；由于这些列值都可以从该维度表的主键值中衍生出来，所以实际上只有主键列会被Cube加入计算。而在Kylin 的具体实现中，往往采用事实表上的外键替代主键进行计算和存储。但是在逻辑上可以认为衍生列来自于维度表的主键。  
使用第二种方法，Kylin会用一个树状结构呈现出所有的列，用户只需要勾选所需要的列即可，Kylin会自动补充其他信息，从而方便用户的操作。请注意，在这里Kylin会把维度表上的列都创建成衍生维度，这也许不是最合适的，在这种情况下请使用第一种方法。


第三页，创建度量。Kylin默认会创建一个Count(1)的度量。可以单击“+Measure"按钮来添加新度量。Kylin支持的度量有：SUM、MIN、MAX、COUNT、COUNT　DISTINCT、ＴＯＰ＿Ｎ、RAW等。请选择需要的度量类型，然后再选择适当的参数（通常为列名）

重复上面的步骤，创建所需要的度量。Kylin可以支持在一个Cube中添加多达上百个度量；添加完成所有度量之后，单击“Next”。

第四页，是关于Cube数据刷新的设置。在这里可以设置自动合并的阈值、数据保留的最短时间，以及第一个Segment的起点时间（如果Cube有分割时间列的话）。

第五页，高级设置。在此页面上可以设置聚合组和Rowkey
Kylin默认会把所有的维度都放在同一个聚合中；如果维度数据较多（例如>10），那么建议用户根据查询的习惯和模式，单击“New Aggregation Group+”，将维度分为多个聚合组。通过使用多个聚合组，可以大大降低Cube中的Cuboid数量。下面来举例说明，如果一个Cube有（M+N)个维度，那么默认它会有2的m+n次方个Cuboid；如果把这些维度分为两个不相交的聚合组，那么Cuboid的数量将被减少为2的m次方+2的n次方。  
在单个聚合组中，可以对维度设置高级属性，例如Mandatory、Hierarchy、Joint等。这几个属性都是为了优化Cube的计算而设计的，了解这些属性的含义对日后更好地使用Cube至关重要。  
Mandatory维度指的是那些总是会出现在where条件或Group By语句里的维度；通过将某个维度指定为Mandatory，Kylin就可以不用预计算那些不包含此维度的Cuboid，从而减少计算量。  
Hierarchy是一组有层级关系的维度，例如：“国家”“省”“市”，这里的“国家”是高级的维度，“省”“市”依次是低级的维度。用户会按高级别维度进行查询，也会按低级别维度进行查询，但在查询低级别维度时，往往都会带上高级别维度的条件，而不会孤立地审视低级别维度的数据。例如，用户单击“国家”作为维度来查询汇总数据，也可能单击“国家”+“省”或者“国家”+“省”+“市”来查询，但是不会跨越国家直接Group By“省”或“市”。通过指定Hierarchy，Kylin可以省略不满足此模式的cuboid。  
Joint是将多个维度组合成一个维度，其通常适用于如下两种情况。
1.总是会在一起查询的维度。  
2.基数很低的维度  
Kylin以Key-Value的方式将Cube存在到HBase中。HBase的key，也就是Rowkey，是由各维度的值拼接而成的；为了更高效地存储这些值，Kylin会对它们进行编码和压缩；每个维度均可以选择合适的编码（Encoding）方式，默认采用的是字典（Dictionary）编码技术；除了字典以外，还有整数（Int）和固定长度（Fixed Length）的编码。  
字典编码是将此维度下所有值构建成一个从string到int的映射表；Kylin会将字典序列化保存，在Cube中存储int值，从而大大减小存储的大小。另外，字典是保持顺序的，即如果字符串A比字符串B大的话，那么A的编码后的int值也会比B编码后的值大；这样可以使得在HBase中进行比较查询的时候，依然使用编码后的值，而无需解码。

字典非常适合于非固定长度的string类型值的维度，而且用户无需指定编码后的长度；但是由于使用字典需要维护一张映射表，因些如果此维度的基数很高，那么字典的大小就非常可观，从而不适合于加载到内存中，在这种情况下就要选择其他的编码方式了。Kylin中字典编码允许的基数上限默认是500万（由参数"kylin.dictioinary.max.cardinality"配置）。  
整数（int）编码适合于对int或bigint类型的值进行编码，它无需额外存储，同时还可以支持很大的基数。用户需要根据值域选择编码的长度。例如有一个手机号码的维度，它是一个11位的数字，如13800138000，我们知道它大于2的31次方，但是小于2的39次方减1，那么使用int(5)即可满足要求，每个值占用5字节，比按字符存储（11字节）要少占一半以上的空间。  

当上面几种编码方式都不适合的时候，就使用固定长度的编码了；此编码方式其实只是将原始值截断或补充成相同长度的一组字节，没有额外的转换，所以空间效率较差，通常只是作为一种权宜手段。  
各维度在Rowkeys中的顺序，对于 查询的性能会产生较明显的影响。在这里用户可以根据查询的模式和习惯，通过拖拽的方式调整各个维度在Rowkeys上的顺序。通常的原则是，将过滤频率较高的列放置在过滤频率较低的列之前，将基数高的列放置在基数低的列之前。这样做的好处是，充分利用过滤条件来缩小在HBase中扫描的范围，从而提高查询的效率。  
第五页，为Cube配置参数。和其他Hadoop工具一样，Kylin使用了很多配置参数以提高录活性，用户可以根据具体的环境、场景等配置不同的参数进行调优。Kylin全局的参数值可在conf/kylin.properties文件中进行配置；如果Cube需要覆盖全局设置的话，则需要在此页面中指定。单击“+Property”按钮，然后输入参数名和参数值。例如“kylin.hbase.region.cut=1",这样此Cube在存储的时候，Kylin将会为每个HTbase Region分配1GB来创建一个HTbase Region。




#构建Cube
新创建的Cube只有定义，而没有计算的数据，它的状态是”DISABLED“，是不会被查询引擎挑中的。要想让Cube有数据，还需要对它进行构建。Cube的构建方式通常有两种：全量构建和增量构建；两者的构建步骤是完全一样的，区别只在于构建时读取的数据源是全集还是子集。  
Cube的构建包含如下步骤，由任务引擎来调度执行。  
1）创建临时的Hive平表（从Hive读取数据）  
2）计算各维度的不同值，并收集各Cuboid的统计数据。  
3）创建并保存字典。  
4）保存Cuboid统计信息。  
5）创建HTable。  
6）计算Cube（一轮或若干轮MapRecue）。  
7）将Cube的计算结果转成HFile。  
8）加载HFile到HBase。  
9）更新Cube元数据。  
10）垃圾回收。  
以上步骤中，前5步是计算Cube而做的准备工作，例如遍历维度值来创建字典，对数据做统计秋估算以创建HTable等；第6）步是真正的Cube计算，取决于所使用的Cube算法，它可能是一轮MapRecue任务，也可能是N（在没有优化的情况下，N可以被视作是维度数）轮迭代的MapRecue。由于Cube运算的中间结果是以SequenceFile的格式存储在HDFS上的，所以为了导入到HBase中，还需要第7）步将这些结果转换成HFile（HBase文件存储格式）。第8）步通过使用HBase BulkLoad工具，将HFile导入到HBase集群，这一步完成之后，HTable就可以查询到数据了。第9）步更新Cube的数据，将此次构建 Segment的状态从”NEW“更新为”ＲＥＡＤＹ＂，表示已经可借查询了。最后一步，清理构建过程中生成的临时文件等垃圾，释放集群资源。　　
Monitor页面会显示当前项目下近期的构建任务。　　



##全量构建和增量构建

###全量构建


###增量构建



##历史数据刷新


##合并

#查询Cube


